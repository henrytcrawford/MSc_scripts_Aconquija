{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9847e561-e904-4aba-8deb-2c75c32e1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from os import path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#define RMSE as a function, since we'll use this in the NN model \n",
    "def rmse(target,prediction):\n",
    "    return(np.sqrt(((target - prediction)**2).sum()/len(target)))\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b54591e-d0b0-403e-a158-88c7ffbf153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some ages dropped\n",
      "some bands dropped\n",
      "(20, 230)\n"
     ]
    }
   ],
   "source": [
    "### PREP DATA ###\n",
    "\n",
    "## MANUAL INPUT ## -- locate file\n",
    "sensor = 'PRISMA' #'PRISMA', 'WV3', 'Landsat8', 'terraspec'\n",
    "target_file = 'C:/Users/htccr/Documents/Aconquija/python_scripts/outputs/' + sensor + '_spots.xlsx'\n",
    "sensor_meta = pd.read_csv('C:/Users/htccr/Documents/Aconquija/python_scripts/keep/'+ sensor + '_meta.csv', header = 0, index_col = None)\n",
    " \n",
    "data = pd.read_excel(target_file, sheet_name = 'band_mean', header = None, index_col = None) # choose sheet: 'band_mean', 'continuum', 'continuum_removed'\n",
    "data_std = pd.read_excel(target_file, sheet_name = 'band_std', header = None, index_col = None)\n",
    "data_vars = pd.read_excel(target_file, sheet_name = 'variables', header = 0, index_col = None)\n",
    "spots_meta = pd.read_excel('C:/Users/htccr/Documents/Aconquija/python_scripts/outputs/spots_meta.xlsx',sheet_name = 'Sheet1', header = 0, index_col = None)\n",
    "\n",
    "# decompact data_vars\n",
    "age = np.array(data_vars['age'])\n",
    "age_sd = np.array(data_vars['age_sd'])\n",
    "age_n = np.array(data_vars['age_n'])\n",
    "fan = np.array(data_vars['fan'])\n",
    "unit = np.array(data_vars['unit'])\n",
    "unique = np.array(data_vars['unique'])\n",
    "pix_count = np.array(data_vars['pix_count'])\n",
    "\n",
    "# decompact sensor metadata (e.g. nm, band names) and create dictionaries\n",
    "band_names = sensor_meta.Band\n",
    "nm_names = sensor_meta.nm.values\n",
    "nm_names = np.round(nm_names,1)\n",
    "band_dict_nm = pd.Series(sensor_meta.Name.values,index=nm_names).to_dict()\n",
    "band_dict_idx  = pd.Series(sensor_meta.Name.values,index=sensor_meta.index.values).to_dict() # create dictionary of band names to wavelength\n",
    "nm_dict = pd.Series(sensor_meta.nm.values,index=sensor_meta.Band).to_dict() # create dictionary of band names to wavelength\n",
    "\n",
    "if 'bad_age_idx' in locals():\n",
    "    del bad_age_idx\n",
    "if 'bad_band_idx' in locals():\n",
    "    del bad_band_idx\n",
    "\n",
    "## MANUAL INPUT ## -- set bands and/or ages to drop\n",
    "bad_band_idx = np.r_[97:110,141:169,226:230] # choose bands to drop by index\n",
    "bad_age_idx = np.where((pix_count == 0) | (pix_count <10))# (age == 3.37) | (age == 16.48) | (age == 78.5) | (age == 314.48) )# | (unit == 'Q2.5a') | (unit == 'Q2.5b')) #  choose age to drop (two decimels)\n",
    "if 'bad_age_idx' in locals():\n",
    "    data = data.drop(np.r_[bad_age_idx], axis=0)\n",
    "    data_std = data_std.drop(np.r_[bad_age_idx], axis=0)\n",
    "    age = np.delete(age, bad_age_idx)\n",
    "    age_sd = np.delete(age_sd, bad_age_idx)\n",
    "    age_n = np.delete(age_n, bad_age_idx)\n",
    "    fan = np.delete(fan, bad_age_idx)\n",
    "    unit = np.delete(unit, bad_age_idx)\n",
    "    unique = np.delete(unique, bad_age_idx)\n",
    "    pix_count = np.delete(pix_count, bad_age_idx)\n",
    "    spots_meta = spots_meta.drop(np.r_[bad_age_idx], axis=0)\n",
    "    \n",
    "    data_plot = data.copy()\n",
    "    data_std_plot = data_std.copy()\n",
    "    print('some ages dropped')\n",
    "else:\n",
    "    data_plot = data.copy()\n",
    "    data_std_plot = data_std.copy()\n",
    "    print('No ages dropped')\n",
    "    \n",
    "# drop chosen values from dataset(s)\n",
    "if 'bad_band_idx' in locals():\n",
    "    #data = data.drop(np.r_[bad_band_idx], axis=1)\n",
    "    #nm_names = np.delete(nm_names, bad_band_idx)\n",
    "    data.iloc[:,bad_band_idx] = np.nan # if bad bands chosen, set band bands as 0 for PCA` #!!change to 0 if NOT normalizign first!!!\n",
    "    data_std.iloc[:,bad_band_idx] = np.nan #!!change to 0 if NOT normalizign first!!!\n",
    "    \n",
    "    # data for plotting (nan instead of 0 for bad bands)\n",
    "    data_plot = data.copy()\n",
    "    data_std_plot = data_std.copy()\n",
    "    data_plot.iloc[:,bad_band_idx] = np.nan\n",
    "    data_std_plot.iloc[:,bad_band_idx] = np.nan\n",
    "    print('some bands dropped')\n",
    "else:\n",
    "    # data for plotting (nan instead of 0 for bad bands)\n",
    "    data_plot = data.copy()\n",
    "    data_std_plot = data_std.copy()\n",
    "    print('No bands dropped')\n",
    "\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0b622f-7565-4794-8449-63d67614b3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.095016  0.087031  0.086043  0.092358  0.097595  0.104654  0.110789   \n",
      "1  0.072552  0.066371  0.066350  0.070230  0.074420  0.080428  0.086002   \n",
      "2  0.092628  0.084281  0.082825  0.088585  0.095247  0.103068  0.108866   \n",
      "3  0.076524  0.071851  0.070685  0.075591  0.079310  0.085356  0.090487   \n",
      "4  0.077176  0.071142  0.070311  0.074786  0.078883  0.084782  0.090278   \n",
      "\n",
      "        7         8         9    ...       216       217       218       219  \\\n",
      "0  0.113885  0.115541  0.120763  ...  0.223382  0.205818  0.205955  0.233426   \n",
      "1  0.088019  0.089246  0.093221  ...  0.178489  0.164673  0.162031  0.184269   \n",
      "2  0.111967  0.113537  0.119765  ...  0.231434  0.212615  0.216693  0.238236   \n",
      "3  0.093323  0.095023  0.099331  ...  0.208660  0.193258  0.187744  0.215425   \n",
      "4  0.092662  0.094946  0.099416  ...  0.206747  0.190891  0.185394  0.210658   \n",
      "\n",
      "        220       221       222       223       224       225  \n",
      "0  0.201663  0.216025  0.164424  0.206316  0.219955  0.211810  \n",
      "1  0.160523  0.173540  0.132066  0.157797  0.173261  0.163852  \n",
      "2  0.205556  0.223030  0.167886  0.215340  0.225796  0.224041  \n",
      "3  0.185074  0.202293  0.156610  0.183150  0.206299  0.192420  \n",
      "4  0.182139  0.199880  0.152988  0.179091  0.202842  0.190318  \n",
      "\n",
      "[5 rows x 185 columns]\n",
      "    age\n",
      "0  0.00\n",
      "1  5.11\n",
      "2  5.30\n",
      "3  5.40\n",
      "4  7.69\n"
     ]
    }
   ],
   "source": [
    "# import model data\n",
    "# x_data\n",
    "x_dat = pd.DataFrame(data)\n",
    "x_dat = x_dat.reset_index(drop=True)\n",
    "x_dat = x_dat.dropna(axis='columns').reset_index(drop=True)\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "x_dat_norm = scaler_x.fit_transform(x_dat)\n",
    "print(x_dat.head())\n",
    "\n",
    "# y data\n",
    "y_dat = pd.DataFrame({'age':age})\n",
    "print(y_dat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88b50a5-ce62-49cd-882f-a2fa980fa0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries etc\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "\n",
    "#run notebook with functions we'll need\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "#         print(excluded)\n",
    "        new_pval = pd.Series(index=excluded, dtype = 'float64')\n",
    "        for new_column in excluded:\n",
    "#             print(included, new_column)\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        \n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = excluded[new_pval.argmin()]\n",
    "#             print(best_feature, included)\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(X.columns[worst_feature], worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f07ae7-2cde-441a-81d3-01dcd7fd87ca",
   "metadata": {},
   "source": [
    "### Run MLR on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b22f80-3a03-49df-b694-ad4faf7462a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize data for MLP nueral network model\n",
    "xy = x_dat\n",
    "xy['age'] = y_dat\n",
    "\n",
    "xy = xy.sample(frac=1).reset_index(drop=True)\n",
    "xy = xy.sample(frac=1).reset_index(drop=True) # shuffle again\n",
    "\n",
    "x = xy.drop(labels = 'age', axis=1)\n",
    "y = xy['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c403d49e-f971-49e8-b2f2-038b2418a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 185)\n",
      "(1, 185)\n"
     ]
    }
   ],
   "source": [
    "# SEQUENTIAL SELECTION OF TRAIN/TEST & STANDARDIZED\n",
    "\n",
    "fracTrain = .95 #fraction of data to use for training\n",
    "ntrain = int(len(y)*fracTrain)\n",
    "\n",
    "x_train = x[:ntrain] #train on n observations\n",
    "y_train = y[:ntrain]\n",
    "\n",
    "x_test = x[ntrain:] #test on remaining observations\n",
    "y_test = y[ntrain:]\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a07e06-ab0c-43a2-8d76-cdf5915d2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_MLR = linear_model.LinearRegression()\n",
    "model = lm_MLR.fit(x_train,y_train)\n",
    "ypred_train = lm_MLR.predict(x_train) #y predicted by MLR\n",
    "ypred_test = lm_MLR.predict(x_test) #y predicted by MLR\n",
    "intercept_MLR = lm_MLR.intercept_ #intercept predicted by MLR\n",
    "coef_MLR = lm_MLR.coef_ #regression coefficients in MLR model\n",
    "R2_train= lm_MLR.score(x_train, y_train) #R-squared value from MLR model\n",
    "R2_test = lm_MLR.score(x_test, y_test) #R-squared value from MLR model\n",
    "\n",
    "\n",
    "print('MLR results:')\n",
    "print('a0 = ' + str(intercept_MLR))\n",
    "print('a1 = ' + str(coef_MLR[0]))\n",
    "print('a2 = ' + str(coef_MLR[1]))\n",
    "print('a3 = ' + str(coef_MLR[2]))\n",
    "print('a4 = ' + str(coef_MLR[3]))\n",
    "#print('a5 = ' + str(coef_MLR[4]))\n",
    "#print('a6 = ' + str(coef_MLR[5]))\n",
    "#print('etc...')\n",
    "R2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46300afb-5e0c-4f09-999e-f7678cc847e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_train, ypred_train)\n",
    "plt.xlab = ('obs')\n",
    "plt.ylab = ('predicted')\n",
    "plt.title = (R2_MLR)\n",
    "R2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd314d-8b81-40ae-b670-8d0bfc8840f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(y_test, ypred_test)\n",
    "plt.xlab = ('obs')\n",
    "plt.ylab = ('predicted')\n",
    "plt.title = (R2_MLR)\n",
    "\n",
    "R2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370b3f91-d0d1-4491-8b62-60903a014c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T.reset_index(drop=True).T\n",
    "y_train = y_train.T.reset_index(drop=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec4eae8-b98d-4085-b191-5b979bd0c4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072552</td>\n",
       "      <td>0.066371</td>\n",
       "      <td>0.066350</td>\n",
       "      <td>0.070230</td>\n",
       "      <td>0.074420</td>\n",
       "      <td>0.080428</td>\n",
       "      <td>0.086002</td>\n",
       "      <td>0.088019</td>\n",
       "      <td>0.089246</td>\n",
       "      <td>0.093221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178489</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.162031</td>\n",
       "      <td>0.184269</td>\n",
       "      <td>0.160523</td>\n",
       "      <td>0.173540</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>0.157797</td>\n",
       "      <td>0.173261</td>\n",
       "      <td>0.163852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079577</td>\n",
       "      <td>0.073320</td>\n",
       "      <td>0.072249</td>\n",
       "      <td>0.077755</td>\n",
       "      <td>0.081926</td>\n",
       "      <td>0.088212</td>\n",
       "      <td>0.093866</td>\n",
       "      <td>0.096745</td>\n",
       "      <td>0.098245</td>\n",
       "      <td>0.102803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223618</td>\n",
       "      <td>0.205754</td>\n",
       "      <td>0.200732</td>\n",
       "      <td>0.229513</td>\n",
       "      <td>0.196232</td>\n",
       "      <td>0.213340</td>\n",
       "      <td>0.164392</td>\n",
       "      <td>0.197503</td>\n",
       "      <td>0.219205</td>\n",
       "      <td>0.206597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082368</td>\n",
       "      <td>0.077101</td>\n",
       "      <td>0.076679</td>\n",
       "      <td>0.082336</td>\n",
       "      <td>0.084593</td>\n",
       "      <td>0.090949</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>0.100718</td>\n",
       "      <td>0.102927</td>\n",
       "      <td>0.107706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233048</td>\n",
       "      <td>0.217796</td>\n",
       "      <td>0.208759</td>\n",
       "      <td>0.238459</td>\n",
       "      <td>0.208309</td>\n",
       "      <td>0.226521</td>\n",
       "      <td>0.178408</td>\n",
       "      <td>0.201354</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.217712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077450</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>0.069072</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>0.083862</td>\n",
       "      <td>0.088644</td>\n",
       "      <td>0.091139</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>0.096264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189033</td>\n",
       "      <td>0.173987</td>\n",
       "      <td>0.174992</td>\n",
       "      <td>0.196828</td>\n",
       "      <td>0.168978</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>0.139680</td>\n",
       "      <td>0.173438</td>\n",
       "      <td>0.185772</td>\n",
       "      <td>0.176120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077176</td>\n",
       "      <td>0.071142</td>\n",
       "      <td>0.070311</td>\n",
       "      <td>0.074786</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>0.084782</td>\n",
       "      <td>0.090278</td>\n",
       "      <td>0.092662</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.099416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206747</td>\n",
       "      <td>0.190891</td>\n",
       "      <td>0.185394</td>\n",
       "      <td>0.210658</td>\n",
       "      <td>0.182139</td>\n",
       "      <td>0.199880</td>\n",
       "      <td>0.152988</td>\n",
       "      <td>0.179091</td>\n",
       "      <td>0.202842</td>\n",
       "      <td>0.190318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.070150</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.056890</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>0.073183</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.079958</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195606</td>\n",
       "      <td>0.178975</td>\n",
       "      <td>0.191459</td>\n",
       "      <td>0.204127</td>\n",
       "      <td>0.178786</td>\n",
       "      <td>0.188211</td>\n",
       "      <td>0.143359</td>\n",
       "      <td>0.193871</td>\n",
       "      <td>0.187603</td>\n",
       "      <td>0.190170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.085625</td>\n",
       "      <td>0.079147</td>\n",
       "      <td>0.079584</td>\n",
       "      <td>0.084716</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>0.095279</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.107614</td>\n",
       "      <td>0.112889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238815</td>\n",
       "      <td>0.221087</td>\n",
       "      <td>0.218034</td>\n",
       "      <td>0.245393</td>\n",
       "      <td>0.211069</td>\n",
       "      <td>0.231297</td>\n",
       "      <td>0.181030</td>\n",
       "      <td>0.211560</td>\n",
       "      <td>0.237286</td>\n",
       "      <td>0.223895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.078435</td>\n",
       "      <td>0.077607</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.104415</td>\n",
       "      <td>0.107677</td>\n",
       "      <td>0.110113</td>\n",
       "      <td>0.115633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223342</td>\n",
       "      <td>0.203991</td>\n",
       "      <td>0.213451</td>\n",
       "      <td>0.232009</td>\n",
       "      <td>0.199888</td>\n",
       "      <td>0.215206</td>\n",
       "      <td>0.161747</td>\n",
       "      <td>0.212239</td>\n",
       "      <td>0.210820</td>\n",
       "      <td>0.216187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.063855</td>\n",
       "      <td>0.058381</td>\n",
       "      <td>0.056903</td>\n",
       "      <td>0.061869</td>\n",
       "      <td>0.065720</td>\n",
       "      <td>0.071742</td>\n",
       "      <td>0.076783</td>\n",
       "      <td>0.079598</td>\n",
       "      <td>0.081136</td>\n",
       "      <td>0.085483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203395</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.185532</td>\n",
       "      <td>0.209826</td>\n",
       "      <td>0.182502</td>\n",
       "      <td>0.197081</td>\n",
       "      <td>0.152599</td>\n",
       "      <td>0.182594</td>\n",
       "      <td>0.198907</td>\n",
       "      <td>0.190579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.092628</td>\n",
       "      <td>0.084281</td>\n",
       "      <td>0.082825</td>\n",
       "      <td>0.088585</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.103068</td>\n",
       "      <td>0.108866</td>\n",
       "      <td>0.111967</td>\n",
       "      <td>0.113537</td>\n",
       "      <td>0.119765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231434</td>\n",
       "      <td>0.212615</td>\n",
       "      <td>0.216693</td>\n",
       "      <td>0.238236</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.223030</td>\n",
       "      <td>0.167886</td>\n",
       "      <td>0.215340</td>\n",
       "      <td>0.225796</td>\n",
       "      <td>0.224041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.065205</td>\n",
       "      <td>0.060808</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>0.064704</td>\n",
       "      <td>0.066925</td>\n",
       "      <td>0.072789</td>\n",
       "      <td>0.078287</td>\n",
       "      <td>0.081263</td>\n",
       "      <td>0.083144</td>\n",
       "      <td>0.087226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196141</td>\n",
       "      <td>0.182702</td>\n",
       "      <td>0.175040</td>\n",
       "      <td>0.201794</td>\n",
       "      <td>0.175730</td>\n",
       "      <td>0.190453</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.195030</td>\n",
       "      <td>0.181913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.070495</td>\n",
       "      <td>0.065091</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.069317</td>\n",
       "      <td>0.071717</td>\n",
       "      <td>0.077917</td>\n",
       "      <td>0.083283</td>\n",
       "      <td>0.085744</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0.091642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>0.184963</td>\n",
       "      <td>0.179548</td>\n",
       "      <td>0.207098</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.195400</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.172391</td>\n",
       "      <td>0.198518</td>\n",
       "      <td>0.185685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.073175</td>\n",
       "      <td>0.063250</td>\n",
       "      <td>0.061596</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>0.072668</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>0.086173</td>\n",
       "      <td>0.088995</td>\n",
       "      <td>0.090327</td>\n",
       "      <td>0.095659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218143</td>\n",
       "      <td>0.201710</td>\n",
       "      <td>0.205545</td>\n",
       "      <td>0.223596</td>\n",
       "      <td>0.189563</td>\n",
       "      <td>0.208192</td>\n",
       "      <td>0.159463</td>\n",
       "      <td>0.207226</td>\n",
       "      <td>0.209973</td>\n",
       "      <td>0.209293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.076524</td>\n",
       "      <td>0.071851</td>\n",
       "      <td>0.070685</td>\n",
       "      <td>0.075591</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>0.085356</td>\n",
       "      <td>0.090487</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.099331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208660</td>\n",
       "      <td>0.193258</td>\n",
       "      <td>0.187744</td>\n",
       "      <td>0.215425</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>0.202293</td>\n",
       "      <td>0.156610</td>\n",
       "      <td>0.183150</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>0.192420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.081191</td>\n",
       "      <td>0.074019</td>\n",
       "      <td>0.072901</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.085377</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.099635</td>\n",
       "      <td>0.102095</td>\n",
       "      <td>0.104375</td>\n",
       "      <td>0.109668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215993</td>\n",
       "      <td>0.199161</td>\n",
       "      <td>0.203535</td>\n",
       "      <td>0.221086</td>\n",
       "      <td>0.193091</td>\n",
       "      <td>0.207681</td>\n",
       "      <td>0.158372</td>\n",
       "      <td>0.202338</td>\n",
       "      <td>0.209409</td>\n",
       "      <td>0.205079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.068087</td>\n",
       "      <td>0.063472</td>\n",
       "      <td>0.061823</td>\n",
       "      <td>0.066896</td>\n",
       "      <td>0.071403</td>\n",
       "      <td>0.078643</td>\n",
       "      <td>0.084494</td>\n",
       "      <td>0.087734</td>\n",
       "      <td>0.089951</td>\n",
       "      <td>0.094863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222239</td>\n",
       "      <td>0.207146</td>\n",
       "      <td>0.204031</td>\n",
       "      <td>0.228892</td>\n",
       "      <td>0.201042</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.170556</td>\n",
       "      <td>0.199093</td>\n",
       "      <td>0.218616</td>\n",
       "      <td>0.209802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.062666</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>0.070995</td>\n",
       "      <td>0.077444</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>0.086004</td>\n",
       "      <td>0.088248</td>\n",
       "      <td>0.092940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210170</td>\n",
       "      <td>0.194951</td>\n",
       "      <td>0.188297</td>\n",
       "      <td>0.215794</td>\n",
       "      <td>0.186407</td>\n",
       "      <td>0.203807</td>\n",
       "      <td>0.158221</td>\n",
       "      <td>0.182148</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>0.194084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.095016</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.086043</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>0.097595</td>\n",
       "      <td>0.104654</td>\n",
       "      <td>0.110789</td>\n",
       "      <td>0.113885</td>\n",
       "      <td>0.115541</td>\n",
       "      <td>0.120763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223382</td>\n",
       "      <td>0.205818</td>\n",
       "      <td>0.205955</td>\n",
       "      <td>0.233426</td>\n",
       "      <td>0.201663</td>\n",
       "      <td>0.216025</td>\n",
       "      <td>0.164424</td>\n",
       "      <td>0.206316</td>\n",
       "      <td>0.219955</td>\n",
       "      <td>0.211810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.075605</td>\n",
       "      <td>0.069742</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.073074</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.090078</td>\n",
       "      <td>0.093074</td>\n",
       "      <td>0.094921</td>\n",
       "      <td>0.099806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218142</td>\n",
       "      <td>0.202566</td>\n",
       "      <td>0.201082</td>\n",
       "      <td>0.224511</td>\n",
       "      <td>0.197078</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.162958</td>\n",
       "      <td>0.202231</td>\n",
       "      <td>0.214359</td>\n",
       "      <td>0.206821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.072552  0.066371  0.066350  0.070230  0.074420  0.080428  0.086002   \n",
       "1   0.079577  0.073320  0.072249  0.077755  0.081926  0.088212  0.093866   \n",
       "2   0.082368  0.077101  0.076679  0.082336  0.084593  0.090949  0.097175   \n",
       "3   0.077450  0.069985  0.069072  0.072671  0.077832  0.083862  0.088644   \n",
       "4   0.077176  0.071142  0.070311  0.074786  0.078883  0.084782  0.090278   \n",
       "5   0.070150  0.059038  0.056890  0.060561  0.067528  0.073183  0.078201   \n",
       "6   0.085625  0.079147  0.079584  0.084716  0.089385  0.095279  0.102000   \n",
       "7   0.083217  0.078435  0.077607  0.083004  0.090908  0.098830  0.104415   \n",
       "8   0.063855  0.058381  0.056903  0.061869  0.065720  0.071742  0.076783   \n",
       "9   0.092628  0.084281  0.082825  0.088585  0.095247  0.103068  0.108866   \n",
       "10  0.065205  0.060808  0.059697  0.064704  0.066925  0.072789  0.078287   \n",
       "11  0.070495  0.065091  0.064500  0.069317  0.071717  0.077917  0.083283   \n",
       "12  0.073175  0.063250  0.061596  0.067261  0.072668  0.080039  0.086173   \n",
       "13  0.076524  0.071851  0.070685  0.075591  0.079310  0.085356  0.090487   \n",
       "14  0.081191  0.074019  0.072901  0.078109  0.085377  0.093121  0.099635   \n",
       "15  0.068087  0.063472  0.061823  0.066896  0.071403  0.078643  0.084494   \n",
       "16  0.069186  0.063721  0.062666  0.067117  0.070995  0.077444  0.082933   \n",
       "17  0.095016  0.087031  0.086043  0.092358  0.097595  0.104654  0.110789   \n",
       "18  0.075605  0.069742  0.068307  0.073074  0.078422  0.085113  0.090078   \n",
       "\n",
       "         7         8         9    ...       175       176       177       178  \\\n",
       "0   0.088019  0.089246  0.093221  ...  0.178489  0.164673  0.162031  0.184269   \n",
       "1   0.096745  0.098245  0.102803  ...  0.223618  0.205754  0.200732  0.229513   \n",
       "2   0.100718  0.102927  0.107706  ...  0.233048  0.217796  0.208759  0.238459   \n",
       "3   0.091139  0.092495  0.096264  ...  0.189033  0.173987  0.174992  0.196828   \n",
       "4   0.092662  0.094946  0.099416  ...  0.206747  0.190891  0.185394  0.210658   \n",
       "5   0.079958  0.080595  0.085106  ...  0.195606  0.178975  0.191459  0.204127   \n",
       "6   0.105042  0.107614  0.112889  ...  0.238815  0.221087  0.218034  0.245393   \n",
       "7   0.107677  0.110113  0.115633  ...  0.223342  0.203991  0.213451  0.232009   \n",
       "8   0.079598  0.081136  0.085483  ...  0.203395  0.188700  0.185532  0.209826   \n",
       "9   0.111967  0.113537  0.119765  ...  0.231434  0.212615  0.216693  0.238236   \n",
       "10  0.081263  0.083144  0.087226  ...  0.196141  0.182702  0.175040  0.201794   \n",
       "11  0.085744  0.087545  0.091642  ...  0.198611  0.184963  0.179548  0.207098   \n",
       "12  0.088995  0.090327  0.095659  ...  0.218143  0.201710  0.205545  0.223596   \n",
       "13  0.093323  0.095023  0.099331  ...  0.208660  0.193258  0.187744  0.215425   \n",
       "14  0.102095  0.104375  0.109668  ...  0.215993  0.199161  0.203535  0.221086   \n",
       "15  0.087734  0.089951  0.094863  ...  0.222239  0.207146  0.204031  0.228892   \n",
       "16  0.086004  0.088248  0.092940  ...  0.210170  0.194951  0.188297  0.215794   \n",
       "17  0.113885  0.115541  0.120763  ...  0.223382  0.205818  0.205955  0.233426   \n",
       "18  0.093074  0.094921  0.099806  ...  0.218142  0.202566  0.201082  0.224511   \n",
       "\n",
       "         179       180       181       182       183       184  \n",
       "0   0.160523  0.173540  0.132066  0.157797  0.173261  0.163852  \n",
       "1   0.196232  0.213340  0.164392  0.197503  0.219205  0.206597  \n",
       "2   0.208309  0.226521  0.178408  0.201354  0.232492  0.217712  \n",
       "3   0.168978  0.183795  0.139680  0.173438  0.185772  0.176120  \n",
       "4   0.182139  0.199880  0.152988  0.179091  0.202842  0.190318  \n",
       "5   0.178786  0.188211  0.143359  0.193871  0.187603  0.190170  \n",
       "6   0.211069  0.231297  0.181030  0.211560  0.237286  0.223895  \n",
       "7   0.199888  0.215206  0.161747  0.212239  0.210820  0.216187  \n",
       "8   0.182502  0.197081  0.152599  0.182594  0.198907  0.190579  \n",
       "9   0.205556  0.223030  0.167886  0.215340  0.225796  0.224041  \n",
       "10  0.175730  0.190453  0.148429  0.168999  0.195030  0.181913  \n",
       "11  0.178200  0.195400  0.150602  0.172391  0.198518  0.185685  \n",
       "12  0.189563  0.208192  0.159463  0.207226  0.209973  0.209293  \n",
       "13  0.185074  0.202293  0.156610  0.183150  0.206299  0.192420  \n",
       "14  0.193091  0.207681  0.158372  0.202338  0.209409  0.205079  \n",
       "15  0.201042  0.216321  0.170556  0.199093  0.218616  0.209802  \n",
       "16  0.186407  0.203807  0.158221  0.182148  0.204794  0.194084  \n",
       "17  0.201663  0.216025  0.164424  0.206316  0.219955  0.211810  \n",
       "18  0.197078  0.211242  0.162958  0.202231  0.214359  0.206821  \n",
       "\n",
       "[19 rows x 185 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230f017-7166-4ce1-8159-55b92dbed85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09566e50-1ffa-4c32-a842-c2cd06f37269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n",
      "Add                             181 with p-value 0.0686812\n",
      "Drop                            181 with p-value 0.0686812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34052/233962231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstepwise_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_in\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resulting features:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34052/547903085.py\u001b[0m in \u001b[0;36mstepwise_selection\u001b[1;34m(X, y, initial_list, threshold_in, threshold_out, verbose)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnew_column\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#             print(included, new_column)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mincluded\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mnew_pval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\env_eosc510\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m                     hasattr(self, 'rank')):\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv_wexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingular_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpinv_extended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m                 self.normalized_cov_params = np.dot(\n\u001b[0;32m    307\u001b[0m                     self.pinv_wexog, np.transpose(self.pinv_wexog))\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\env_eosc510\\lib\\site-packages\\statsmodels\\tools\\tools.py\u001b[0m in \u001b[0;36mpinv_extended\u001b[1;34m(x, rcond)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     res = np.dot(np.transpose(vt), np.multiply(s[:, np.core.newaxis],\n\u001b[0m\u001b[0;32m    418\u001b[0m                                                np.transpose(u)))\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#now, use stepwise regression to find which predictors to use\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "result = stepwise_selection(x_train, y_train, threshold_in=.1, threshold_out=0.01)\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc552fab-54b0-4d4e-8e18-4aca17897160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 0 coefficients at all nm values that are 'bad bands'\n",
    "coef_MLR_all = list(coef_MLR)\n",
    "\n",
    "for idx in bad_band_idx:\n",
    "    coef_MLR_all.insert(idx,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd52029-257f-4c84-a93b-a1e664e25cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nm_names, coef_MLR_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5745c-f85a-46ec-9cea-425164b55a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_names[np.where(coef_MLR_all == np.min(coef_MLR_all))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_eosc510",
   "language": "python",
   "name": "env_eosc510"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
